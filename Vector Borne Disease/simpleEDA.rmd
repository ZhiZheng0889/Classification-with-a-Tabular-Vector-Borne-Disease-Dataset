---
title: "R Notebook"
output: html_notebook
---

```{r}
library(httr)
library(readr)
library(reticulate)
library(keras)

```


```{r}
test_data_url <- "https://www.dropbox.com/s/0a2tse6lyxpg1h5/test.csv?dl=1"
train_data_url <- "https://www.dropbox.com/s/z1jjzqwnmx6opxi/train.csv?dl=1"

test_df <- read_csv(url(test_data_url))
train_df <- read_csv(url(train_data_url))


```

```{r}
# Dummy preprocess function (replace with your actual preprocessing)
preprocess <- function(df) {
  x <- df[, -1] # Remove the target column (replace with actual column name)
  y <- df[, 1]  # Extract the target column (replace with actual column name)
  
  return(list(x = x, y = y))
}

train_data <- preprocess(train_df)
test_data <- preprocess(test_df)

```

```{r}
target_labels <- unique(train_data$y)

# One-hot encode the target labels
train_labels <- to_categorical(as.integer(factor(train_data$y, levels = target_labels)) - 1)

```

```{r}
model <- keras_model_sequential() %>%
  layer_dense(units = 128, activation = "relu", input_shape = c(input_dim)) %>%
  layer_dense(units = 64, activation = "relu") %>%
  layer_dense(units = num_classes, activation = "softmax")

model %>% compile(
  loss = "categorical_crossentropy",
  optimizer = optimizer_adam(learning_rate = 0.001),
  metrics = c("accuracy")
)


```

```{r}
# Preprocess the datasets
preprocess <- function(df) {
  x <- df[, !(names(df) %in% c("id", "prognosis"))]  # Remove the id and prognosis columns
  y <- df$prognosis  # Extract the prognosis column
  
  return(list(x = x, y = y))
}

train_data <- preprocess(train_df)
test_data <- preprocess(test_df)

# Encode the target labels
target_labels <- unique(train_data$y)

# One-hot encode the target labels
train_labels <- to_categorical(as.integer(factor(train_data$y, levels = target_labels)) - 1)

input_dim <- ncol(train_data$x)
num_classes <- length(target_labels)

model <- keras_model_sequential() %>%
  layer_dense(units = 128, activation = "relu", input_shape = c(input_dim)) %>%
  layer_dense(units = 64, activation = "relu") %>%
  layer_dense(units = num_classes, activation = "softmax")

model %>% compile(
  loss = "categorical_crossentropy",
  optimizer = optimizer_adam(learning_rate = 0.001),
  metrics = c("accuracy")
)



```

```{r}
predicted_probabilities <- model %>% predict_proba(as.matrix(test_data$x))

```

```{r}
source_python("helper_functions.py")

```

```{r}
top_3_predictions <- top3(predicted_probabilities)

```

```{r}
# Assuming you have a function named 'get_actual_labels' that takes a data frame as input and returns a list of the actual labels for each data point
get_actual_labels <- function(df) {
  return(lapply(df$target_column, function(label) c(label))) # Replace 'target_column' with the actual target column name in your dataset
}

actual_labels <- get_actual_labels(train_df)
mapk_score <- mapk(actual_labels, predicted_probabilities, k = 3)

```

```{r}
# Convert the top 3 predictions to the required submission format
submission_prognosis <- apply(top_3_predictions, 1, paste, collapse = " ")

# Create a submission data frame
submission_df <- data.frame(id = test_df$id, prognosis = submission_prognosis)

# Save the submission data frame to a CSV file
write_csv(submission_df, "submission.csv", col_names = TRUE)

```


