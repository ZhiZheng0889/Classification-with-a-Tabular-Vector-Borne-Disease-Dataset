---
title: "R Notebook"
output: html_notebook
---

```{r}
# Load the required packages
library(randomForest)
library(caret)
library(MASS)

# Read the train and test datasets
train <- read.csv("https://www.dropbox.com/s/z1jjzqwnmx6opxi/train.csv?dl=1")
test <- read.csv("https://www.dropbox.com/s/0a2tse6lyxpg1h5/test.csv?dl=1")

# Convert the prognosis column to a factor
train$prognosis <- as.factor(train$prognosis)

# Extract the top 5 most important features
top_features <- row.names(importance(rf_model))[1:4]

# Create a formula with the best subset of features
best_formula <- as.formula(paste("prognosis ~", paste(top_features, collapse = " + ")))

# Train the Random Forest model with the best subset of features
set.seed(123)
best_rf_model <- randomForest(best_formula, data = train, importance = TRUE)

# Make predictions using the trained model with the best subset of features
best_predictions <- predict(best_rf_model, test[, top_features])

# Create the submission file
best_submission <- data.frame(id = test$id, prognosis = best_predictions)
write.csv(best_submission, "best_submission.csv", row.names = FALSE)



```

```{r}
# Load the required packages
library(randomForest)
library(caret)
library(MASS)

# Read the train and test datasets
train <- read.csv("https://www.dropbox.com/s/z1jjzqwnmx6opxi/train.csv?dl=1")
test <- read.csv("https://www.dropbox.com/s/0a2tse6lyxpg1h5/test.csv?dl=1")

# Convert the prognosis column to a factor
train$prognosis <- as.factor(train$prognosis)

# Train an initial random forest model
set.seed(123)
initial_rf_model <- randomForest(prognosis ~ ., data = train, importance = TRUE)

# Extract the top 4 most important features
top_features <- row.names(importance(initial_rf_model))[1:6]
print(top_features)

# Create a formula with the best subset of features
best_formula <- as.formula(paste("prognosis ~", paste(top_features, collapse = " + ")))

# Train the Random Forest model with the best subset of features
set.seed(123)
best_rf_model <- randomForest(best_formula, data = train, importance = TRUE)

# Make predictions using the trained model with the best subset of features
best_predictions <- predict(best_rf_model, test[, top_features])

# Create the submission file
best_submission <- data.frame(id = test$id, prognosis = best_predictions)
write.csv(best_submission, "best_submission.csv", row.names = FALSE)

```


```{r}
# Load required package
library(caret)

# Make probability predictions using the trained model with the best subset of features
proba_predictions <- predict(best_rf_model, test[, top_features], type = "prob")

# Get the top 3 predicted classes for each ID
top_3_predictions <- apply(proba_predictions, 1, function(x) names(sort(x, decreasing = TRUE))[1:3])

# Combine the top 3 predictions into a single string separated by spaces
combined_predictions <- apply(top_3_predictions, 2, paste, collapse = " ")

# Create the submission file
submission_mpa3 <- data.frame(id = test$id, prognosis = combined_predictions)
write.csv(submission_mpa3, "submission_mpa3.csv", row.names = FALSE)

```

```{r}
library(leaps)
forward <- regsubsets(prognosis ~ ., data = train, method = "forward")
summary(forward)

```

```{r}
backward <- regsubsets(prognosis ~ ., data = train, method = "backward")
summary(backward)

```


```{r}
library(glmnet)

# Assuming your training data is stored in a data frame called 'train' 
# and the target variable is called 'prognosis'

# Create a matrix of predictor variables
x <- model.matrix(prognosis ~ ., data = train)[, -1]

# Convert the target variable to a factor
y <- as.factor(train$prognosis)

# Fit the multinomial model using glmnet
fit_multinomial <- glmnet(x, y, family = "multinomial", alpha = 1)

# Perform cross-validation with the multinomial family
cv_multinomial <- cv.glmnet(x, y, family = "multinomial", alpha = 1)

# Obtain the coefficients at lambda.min
coef(cv_multinomial, s = "lambda.min")


```

```{r}
library(glmnet)

# Assuming your training data is stored in a data frame called 'train' 
# and the target variable is called 'prognosis'

# Create a matrix of predictor variables
x <- model.matrix(prognosis ~ ., data = train)[, -1]

# Convert the target variable to a factor
y <- as.factor(train$prognosis)

# Fit the ridge regression model using glmnet
ridge_model <- glmnet(x, y, family = "multinomial", alpha = 0)

# Perform cross-validation with the multinomial family
cv_ridge <- cv.glmnet(x, y, family = "multinomial", alpha = 0)

# Obtain the coefficients at lambda.min
coef(cv_ridge, s = "lambda.min")


```

```{r}
library(glmnet)

# Assuming your training data is stored in a data frame called 'train' 
# and the target variable is called 'prognosis'

# Create a matrix of predictor variables
x <- model.matrix(prognosis ~ ., data = train)[, -1]

# Convert the target variable to a factor
y <- as.factor(train$prognosis)

# Set the alpha value between 0 and 1 for the balance between Ridge and LASSO
alpha_val <- 0.5

# Fit the elastic net model using glmnet
elastic_net_model <- glmnet(x, y, family = "multinomial", alpha = alpha_val)

# Perform cross-validation with the multinomial family
cv_elastic_net <- cv.glmnet(x, y, family = "multinomial", alpha = alpha_val)

# Obtain the coefficients at lambda.min
coef(cv_elastic_net, s = "lambda.min")


```

```{r}
library(caret)
library(randomForest)  # If you haven't already loaded it

# Assuming your training data is stored in a data frame called 'train' 
# and the target variable is called 'prognosis'

# Create a matrix of predictor variables
x <- model.matrix(prognosis ~ ., data = train)[, -1]

# Convert the target variable to a factor
y <- as.factor(train$prognosis)

# Set up the control for RFE using caret and random forest
ctrl <- rfeControl(functions = rfFuncs, method = "cv", number = 10)

# Perform Recursive Feature Elimination (RFE)
rfe_result <- rfe(x, y, sizes = 1:ncol(x), rfeControl = ctrl)

# Print the RFE result
print(rfe_result)

```



